{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c79139",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db852bb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Mask R-CNN\n",
    "Train on the toy Balloon dataset and implement color splash effect.\n",
    "\n",
    "Copyright (c) 2018 Matterport, Inc.\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "Written by Waleed Abdulla\n",
    "Edited for general application by Soumya Yadav (Psoumyadav@gmail.com)\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "    \n",
    "    #    access venv :\n",
    "    myvenv/Script/activate\n",
    "    #    install requirements:\n",
    "    pip install -r requirements_mouad2.txt\n",
    "\n",
    "    #  test model on an image with latest trained model:\n",
    "    python custom2.py splash --weights=last --image=\".\\\\dataset\\\\train\\\\hat (24).jpg\"\n",
    "        \n",
    "\n",
    "    # Train a new model starting from pre-trained COCO weights\n",
    "    python3 custom2.py train --dataset=/path/to/balloon/dataset --weights=coco\n",
    "\n",
    "    # Resume training a model that you had trained earlier\n",
    "    python3 custom2.py train --dataset=/path/to/balloon/dataset --weights=last\n",
    "\n",
    "    # Train a new model starting from ImageNet weights\n",
    "    python3 balloon.py train --dataset=/path/to/balloon/dataset --weights=imagenet\n",
    "\n",
    "    # Apply color splash to an image\n",
    "    python3 balloon.py splash --weights=/path/to/weights/file.h5 --image=<URL or path to file>\n",
    "\n",
    "    # Apply color splash to video using the last weights you trained\n",
    "    python3 balloon.py splash --weights=last --video=<URL or path to file>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36ef1d5",
   "metadata": {
    "lines_to_next_cell": 1,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import argparse\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.visualize import display_instances\n",
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if a GPU is available in TensorFlow 1.x\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU\")\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"..\\\\..\\\\\")\n",
    "\n",
    "#Directory to save logs and model checkpoints, if not provided\n",
    "#through the command line argumment --logs\n",
    "#DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR,\"logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    NAME = \"hat\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # Background + hat\n",
    "    STEPS_PER_EPOCH = 20\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "class CustomDataset(utils.Dataset):\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "        self.add_class(\"hat\", 1, \"hat\")\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"safety_hat_json.json\")))\n",
    "\n",
    "        for image_id, info in annotations.items():\n",
    "            polygons = [region['shape_attributes'] for region in info['regions']]\n",
    "            objects = [region['region_attributes']['safety_hat'] for region in info['regions']]\n",
    "            num_ids = [1 if name == \"hat\" else 0 for name in objects]\n",
    "            image_path = os.path.join(dataset_dir, info['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "            self.add_image(\n",
    "                \"hat\",\n",
    "                image_id=info['filename'],\n",
    "                path=image_path,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"hat\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        \n",
    "        num_ids = image_info['num_ids']\n",
    "        mask = np.zeros([image_info[\"height\"], image_info[\"width\"], len(image_info[\"polygons\"])], dtype=np.uint8)\n",
    "        for i, p in enumerate(image_info[\"polygons\"]):\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        return self.image_info[image_id][\"path\"]\n",
    "\n",
    "def train(model, dataset_dir, epochs=20):\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(dataset_dir, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    dataset_val = CustomDataset()\n",
    "    dataset_val.load_custom(dataset_dir, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "   # Log training losses\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=epochs,\n",
    "                layers='heads')\n",
    "    \n",
    "    # Save the training log\n",
    "    with open(os.path.join(DEFAULT_LOGS_DIR, \"training_log.txt\"), \"w\") as log_file:\n",
    "        log_file.write(\"Training log:\\n\")\n",
    "        log_file.write(str(model.keras_model.history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5025aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, config):\n",
    "    # Initialize confusion matrix parameters\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for image_id in dataset.image_ids:\n",
    "        image, _, gt_class_ids, _, _ = modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        \n",
    "        y_true.extend(gt_class_ids)\n",
    "        y_pred.extend(r['class_ids'])\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"BG\", \"Hat\"])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "def plot_losses(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342389c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def apply_splash(model, image_path=None, video_path=None):\n",
    "    if image_path:\n",
    "        image = skimage.io.imread(image_path)\n",
    "        result = model.detect([image], verbose=1)[0]\n",
    "\n",
    "        # Display results\n",
    "        display_instances(image, result['rois'], result['masks'], result['class_ids'], \n",
    "                          [\"BG\", \"hat\"], result['scores'])\n",
    "        plt.show()\n",
    "\n",
    "    elif video_path:\n",
    "        # Video handling code can go here if needed\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set variables directly instead of parsing arguments\n",
    "    command = \"train\"  # 'train' or 'splash'\n",
    "    dataset_path = \"./datasets\"  # Replace with your dataset path\n",
    "    weights = \"coco\"  # Use \"coco\", \"last\", or the specific path to your weights file\n",
    "    image_path = None  # Set an image path if using 'splash' command\n",
    "\n",
    "    config = CustomConfig()\n",
    "    model_dir = DEFAULT_LOGS_DIR\n",
    "    model = modellib.MaskRCNN(mode=\"training\" if command == \"train\" else \"inference\", config=config, model_dir=model_dir)\n",
    "\n",
    "    # Determine weights path based on the weights variable\n",
    "    if weights.lower() == \"coco\":\n",
    "        weights_path = COCO_WEIGHTS_PATH\n",
    "    elif weights.lower() == \"last\":\n",
    "        weights_path = model.find_last()\n",
    "    elif weights.lower() == \"imagenet\":\n",
    "        weights_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        weights_path = weights\n",
    "\n",
    "    # Load weights, excluding class-specific layers for compatibility if using COCO weights\n",
    "    if weights.lower() == \"coco\":\n",
    "        model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # Execute based on the command variable\n",
    "    if command == \"train\":\n",
    "        train(model, dataset_path, epochs=15)\n",
    "    elif command == \"splash\":\n",
    "        assert image_path, \"Please provide an image path for splash mode\"\n",
    "        apply_splash(model, image_path=image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c904f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4893297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8deea1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8998e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67ccbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eafafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4621882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a25ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
