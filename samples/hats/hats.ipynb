{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c79139",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db852bb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Mask R-CNN\n",
    "Train on the toy Balloon dataset and implement color splash effect.\n",
    "\n",
  
    "------------------------------------------------------------\n",
    "\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "    \n",
    "    #    access venv :\n",
    "    myvenv/Script/activate\n",
    "    #    install requirements:\n",
    
    "\n",
    "    #  test model on an image with latest trained model:\n",
    "    python custom2.py splash --weights=last --image=\".\\\\dataset\\\\train\\\\hat (24).jpg\"\n",
    "        \n",
    "\n",
    "    # Train a new model starting from pre-trained COCO weights\n",
    "    python3 custom2.py train --dataset=/path/to/balloon/dataset --weights=coco\n",
    "\n",
    "    # Resume training a model that you had trained earlier\n",
    "    python3 custom2.py train --dataset=/path/to/balloon/dataset --weights=last\n",
    "\n",
    "    # Train a new model starting from ImageNet weights\n",
    "    python3 balloon.py train --dataset=/path/to/balloon/dataset --weights=imagenet\n",
    "\n",
    "    # Apply color splash to an image\n",
    "    python3 balloon.py splash --weights=/path/to/weights/file.h5 --image=<URL or path to file>\n",
    "\n",
    "    # Apply color splash to video using the last weights you trained\n",
    "    python3 balloon.py splash --weights=last --video=<URL or path to file>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36ef1d5",
   "metadata": {
    "lines_to_next_cell": 1,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import argparse\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.visualize import display_instances\n",
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if a GPU is available in TensorFlow 1.x\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU\")\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"..\\\\..\\\\\")\n",
    "\n",
    "#Directory to save logs and model checkpoints, if not provided\n",
    "#through the command line argumment --logs\n",
    "#DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR,\"logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    NAME = \"hat\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # Background + hat\n",
    "    STEPS_PER_EPOCH = 20\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "class CustomDataset(utils.Dataset):\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "        self.add_class(\"hat\", 1, \"hat\")\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"safety_hat_json.json\")))\n",
    "\n",
    "        for image_id, info in annotations.items():\n",
    "            polygons = [region['shape_attributes'] for region in info['regions']]\n",
    "            objects = [region['region_attributes']['safety_hat'] for region in info['regions']]\n",
    "            num_ids = [1 if name == \"hat\" else 0 for name in objects]\n",
    "            image_path = os.path.join(dataset_dir, info['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "            self.add_image(\n",
    "                \"hat\",\n",
    "                image_id=info['filename'],\n",
    "                path=image_path,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"hat\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        \n",
    "        num_ids = image_info['num_ids']\n",
    "        mask = np.zeros([image_info[\"height\"], image_info[\"width\"], len(image_info[\"polygons\"])], dtype=np.uint8)\n",
    "        for i, p in enumerate(image_info[\"polygons\"]):\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        return self.image_info[image_id][\"path\"]\n",
    "\n",
    "def train(model, dataset_dir, epochs=20):\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(dataset_dir, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    dataset_val = CustomDataset()\n",
    "    dataset_val.load_custom(dataset_dir, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "   # Log training losses\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=epochs,\n",
    "                layers='heads')\n",
    "    \n",
    "    # Save the training log\n",
    "    with open(os.path.join(DEFAULT_LOGS_DIR, \"training_log.txt\"), \"w\") as log_file:\n",
    "        log_file.write(\"Training log:\\n\")\n",
    "        log_file.write(str(model.keras_model.history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5025aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, config):\n",
    "    # Initialize confusion matrix parameters\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for image_id in dataset.image_ids:\n",
    "        image, _, gt_class_ids, _, _ = modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        \n",
    "        y_true.extend(gt_class_ids)\n",
    "        y_pred.extend(r['class_ids'])\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"BG\", \"Hat\"])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "def plot_losses(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342389c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def apply_splash(model, image_path=None, video_path=None):\n",
    "    if image_path:\n",
    "        image = skimage.io.imread(image_path)\n",
    "        result = model.detect([image], verbose=1)[0]\n",
    "\n",
    "        # Display results\n",
    "        display_instances(image, result['rois'], result['masks'], result['class_ids'], \n",
    "                          [\"BG\", \"hat\"], result['scores'])\n",
    "        plt.show()\n",
    "\n",
    "    elif video_path:\n",
    "        # Video handling code can go here if needed\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set variables directly instead of parsing arguments\n",
    "    command = \"train\"  # 'train' or 'splash'\n",
    "    dataset_path = \"./datasets\"  # Replace with your dataset path\n",
    "    weights = \"coco\"  # Use \"coco\", \"last\", or the specific path to your weights file\n",
    "    image_path = None  # Set an image path if using 'splash' command\n",
    "\n",
    "    config = CustomConfig()\n",
    "    model_dir = DEFAULT_LOGS_DIR\n",
    "    model = modellib.MaskRCNN(mode=\"training\" if command == \"train\" else \"inference\", config=config, model_dir=model_dir)\n",
    "\n",
    "    # Determine weights path based on the weights variable\n",
    "    if weights.lower() == \"coco\":\n",
    "        weights_path = COCO_WEIGHTS_PATH\n",
    "    elif weights.lower() == \"last\":\n",
    "        weights_path = model.find_last()\n",
    "    elif weights.lower() == \"imagenet\":\n",
    "        weights_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        weights_path = weights\n",
    "\n",
    "    # Load weights, excluding class-specific layers for compatibility if using COCO weights\n",
    "    if weights.lower() == \"coco\":\n",
    "        model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # Execute based on the command variable\n",
    "    if command == \"train\":\n",
    "        train(model, dataset_path, epochs=15)\n",
    "    elif command == \"splash\":\n",
    "        assert image_path, \"Please provide an image path for splash mode\"\n",
    "        apply_splash(model, image_path=image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c904f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4893297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8deea1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8998e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67ccbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eafafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4621882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a25ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
